{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875fcd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Pkg\n",
    "Pkg.activate(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9266b436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (only needed the first time)\n",
    "Pkg.instantiate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c6d3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux\n",
    "using CUDA\n",
    "using Plots\n",
    "using PyCall\n",
    "using MLDatasets: MNIST\n",
    "using MLDataPattern\n",
    "using Flux.Data: DataLoader\n",
    "using FluxTraining\n",
    "\n",
    "# \"Accept\" terms when downloading MNIST image data\n",
    "ENV[\"DATADEPS_ALWAYS_ACCEPT\"] = true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c678830f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download CUDA packages (first time only) and show info about their version\n",
    "CUDA.versioninfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990ab133",
   "metadata": {},
   "source": [
    "# Handwriting recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bb05a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load handwritten digits dataset\n",
    "x_data = reshape(MNIST.traintensor(Float32), 28, 28, 1, :)\n",
    "y_data = Flux.onehotbatch(MNIST.trainlabels(), 0:9)\n",
    "\n",
    "# Split into training, validation, testing\n",
    "traindata, valdata, testdata = splitobs((x_data, y_data), at=(0.9, 0.05))\n",
    "\n",
    "# Show sizes\n",
    "@show size(traindata[1]) size(valdata[1]) size(testdata[1])\n",
    "@show size(traindata[2]) size(valdata[2]) size(testdata[2]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a0f1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot some images\n",
    "plots = map(1:25) do i\n",
    "    p = plot(Gray.(1 .- testdata[1][:, :, 1, i])'; yaxis=nothing, xaxis=nothing)\n",
    "    label = Flux.onecold(testdata[2][:, i], 0:9)\n",
    "    title!(p, string(label), titlefontsize=8)\n",
    "end\n",
    "plot(plots...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98e2547",
   "metadata": {},
   "source": [
    "We will next define the following structure of the neural network:\n",
    "\n",
    "![](model.png)\n",
    "\n",
    "The input will be the image, the output will be the 10 probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d590c036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the neural network.\n",
    "model = Chain(\n",
    "    Conv((3, 3), 1 => 6, relu),\n",
    "    AdaptiveMaxPool((13, 13)),\n",
    "    Conv((3, 3), 6 => 16, relu),\n",
    "    AdaptiveMaxPool((5, 5)),\n",
    "    flatten,\n",
    "    Dense(400, 100, relu),\n",
    "    Dense(100, 84, relu),\n",
    "    Dense(84, 10),\n",
    "    softmax\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7edaf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "loss = Flux.Losses.crossentropy\n",
    "opt  = Flux.Optimise.ADAM()\n",
    "\n",
    "train_iterator = DataLoader(traindata, batchsize=250, shuffle=true)\n",
    "valid_iterator = DataLoader(valdata,   batchsize=250, shuffle=true)\n",
    "learner        = Learner(model, (train_iterator, valid_iterator),\n",
    "                         opt, loss, Metrics(accuracy), ToGPU())\n",
    "\n",
    "nepochs = 10\n",
    "FluxTraining.fit!(learner, nepochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36425f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot learning rate\n",
    "training_loss   = learner.cbstate.metricsepoch[TrainingPhase()][:Loss].values\n",
    "validation_loss = learner.cbstate.metricsepoch[ValidationPhase()][:Loss].values\n",
    "\n",
    "p = plot(training_loss, label=\"Training loss\")\n",
    "p = plot!(p, validation_loss, label=\"Validation loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72022c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model.\n",
    "test_pred = model(testdata[1])\n",
    "\n",
    "@show loss(test_pred, testdata[2])\n",
    "@show accuracy(test_pred, testdata[2]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8934a8f3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plots = map(1:25) do i\n",
    "    p = plot(Gray.(1 .- testdata[1][:, :, 1, i])'; yaxis=nothing, xaxis=nothing)\n",
    "    prediction = findmax(vec(model(testdata[1][:, :, :, i:i])))\n",
    "    title!(p, \"$(prediction[2]-1) -> $(round(100prediction[1], digits=1))%\",\n",
    "    titlefontsize=8)\n",
    "end\n",
    "plot(plots...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ccde5a",
   "metadata": {},
   "source": [
    "# Deep convolutional autoencoder\n",
    "\n",
    "![](auto.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2a2bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the autoencoder network.\n",
    "encoder = Chain(\n",
    "    Conv((3, 3),  1 => 16, relu, pad=SamePad()),\n",
    "    MaxPool((2, 2),              pad=SamePad()),\n",
    "    Conv((3, 3), 16 =>  8, relu, pad=SamePad()),\n",
    "    MaxPool((2, 2),              pad=SamePad()),\n",
    "    Conv((3, 3),  8 =>  2, relu, pad=SamePad()),\n",
    "    MaxPool((2, 2),              pad=SamePad()),\n",
    ")\n",
    "\n",
    "decoder = Chain(\n",
    "    Conv((3, 3),  2 =>  2, relu, pad=SamePad()),\n",
    "    Upsample(scale=(2, 2)),\n",
    "    Conv((3, 3),  2 =>  8, relu, pad=SamePad()),\n",
    "    Upsample(scale=(2, 2)),\n",
    "    Conv((3, 3),  8 => 16, relu),\n",
    "    Upsample(scale=(2, 2)),\n",
    "    Conv((3, 3), 16 => 1,  sigmoid, pad=SamePad()),\n",
    ")\n",
    "    \n",
    "autoencoder = Chain(encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ba7433",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Gather training data for autoencoder:\n",
    "traindata, valdata, testdata = splitobs((x_data, x_data), at=(0.9, 0.05))\n",
    "\n",
    "# Train the model\n",
    "loss = Flux.Losses.mse\n",
    "opt  = Flux.Optimise.ADADelta()\n",
    "\n",
    "train_iterator = DataLoader(traindata, batchsize=128, shuffle=true)\n",
    "valid_iterator = DataLoader(valdata,   batchsize=128, shuffle=true)\n",
    "learner        = Learner(autoencoder, (train_iterator, valid_iterator),\n",
    "                         opt, loss, ToGPU())\n",
    "\n",
    "nepochs = 30\n",
    "FluxTraining.fit!(learner, nepochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3ee25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot learning rate\n",
    "training_loss   = learner.cbstate.metricsepoch[TrainingPhase()][:Loss].values\n",
    "validation_loss = learner.cbstate.metricsepoch[ValidationPhase()][:Loss].values\n",
    "\n",
    "p = plot(training_loss, label=\"Training loss\")\n",
    "p = plot!(p, validation_loss, label=\"Validation loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf6a975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model.\n",
    "@show loss(autoencoder(testdata[1]), testdata[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1f3470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode and then decode some test data.\n",
    "encoded_imgs = encoder(testdata[1])\n",
    "decoded_imgs = decoder(encoded_imgs);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bb57d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plots = map(1:10) do i\n",
    "    p = plot(Gray.(1 .- testdata[1][:, :, 1, i])';  yaxis=nothing, xaxis=nothing)\n",
    "    q = plot(Gray.(1 .- decoded_imgs[:, :, 1, i])'; yaxis=nothing, xaxis=nothing)\n",
    "    (p, q)\n",
    "end\n",
    "plot(plots..., layout=(10, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d3ea5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the latent spaces.\n",
    "plots = map(1:10) do i\n",
    "    latent_reshaped = reshape(encoded_imgs[:, :, :, i], 4, 8)\n",
    "    plot(Gray.(1 .- latent_reshaped); yaxis=nothing, xaxis=nothing)\n",
    "end\n",
    "plot(plots...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db72882f",
   "metadata": {},
   "source": [
    "## Solving the Schrödinger Equation using Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66351e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use pickle to import data and get it to the julia world\n",
    "py\"\"\"\n",
    "import pickle\n",
    "with open('V.db', 'rb') as f:\n",
    "    V = pickle.load(f)\n",
    "with open('density.db', 'rb') as f:\n",
    "    n = pickle.load(f)\n",
    "with open('E.db', 'rb') as f:\n",
    "    E = pickle.load(f)\n",
    "\"\"\"\n",
    "V, ρ, E = py\"(V, n, E)\"\n",
    "n_samples, n_grid = size(V)\n",
    "\n",
    "# Reshape appropriately\n",
    "V = reshape(Float32.(V'), n_grid, 1, n_samples)\n",
    "ρ = reshape(Float32.(ρ'), n_grid, 1, n_samples)\n",
    "E = reshape(Float32.(E),          1, n_samples);\n",
    "\n",
    "# Split into training, validation, testing\n",
    "traindata, valdata, testdata = splitobs((V, E), at=(0.5, 0.25))\n",
    "\n",
    "# Show sizes\n",
    "@show size(traindata[1]) size(valdata[1]) size(testdata[1])\n",
    "@show size(traindata[2]) size(valdata[2]) size(testdata[2]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98f86cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the neural network.\n",
    "V_to_E = Chain(\n",
    "    Conv((3, ), 1 => 6, relu),\n",
    "    MaxPool((2, )),\n",
    "    Conv((3, ), 6 => 16, relu),\n",
    "    MaxPool((2, )),\n",
    "    flatten,\n",
    "    Dense(224, 120, relu),\n",
    "    # Dropout(0.5),\n",
    "    Dense(120, 50, relu),\n",
    "    # Dropout(0.5),\n",
    "    Dense(50, 1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d885b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "loss = Flux.Losses.mse\n",
    "opt  = Flux.Optimise.ADADelta()\n",
    "\n",
    "train_iterator = DataLoader(traindata, batchsize=250, shuffle=true)\n",
    "valid_iterator = DataLoader(valdata,   batchsize=250, shuffle=true)\n",
    "learner        = Learner(V_to_E, (train_iterator, valid_iterator),\n",
    "                         opt, loss, ToGPU())\n",
    "\n",
    "nepochs = 20\n",
    "FluxTraining.fit!(learner, nepochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1aab05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot learning rate\n",
    "training_loss   = learner.cbstate.metricsepoch[TrainingPhase()][:Loss].values\n",
    "validation_loss = learner.cbstate.metricsepoch[ValidationPhase()][:Loss].values\n",
    "\n",
    "p = plot(training_loss, label=\"Training loss\")\n",
    "p = plot!(p, validation_loss, label=\"Validation loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f09c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model.\n",
    "@show loss(V_to_E(testdata[1]), testdata[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766cf82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "E_pred = V_to_E(testdata[1])\n",
    "plots = map(enumerate(CartesianIndices((5, 5)))) do (k, I)\n",
    "    # ρ_test[:, 1, k]\n",
    "    p = plot(testdata[1][:, 1, k]; yaxis=nothing, xaxis=nothing, color=:red, label=\"\")\n",
    "    hline!(p, testdata[2][:, k]; color=:blue, linestyle=:dash, label=\"\")\n",
    "    hline!(p, E_pred[:, k]; color=:green, label=\"\")\n",
    "    ylims!(p, (NaN, 0.5))\n",
    "end\n",
    "plot(plots...)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.0",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
